# 5. Template System and Self-Consistent Refinement

The **Template System** is the core interface between raw scientific documents and structured knowledge within the Discovery Engine. It defines how LLMs extract, justify, and encode knowledge artifacts, and evolves dynamically to reflect the structure of the literature itself.

---

## 5.1 Purpose of the Template System

The goal is to **transform unstructured prose into semantically explicit, machine-verifiable knowledge artifacts**, with minimal hallucination and maximal reusability.

### Motivation

| Challenge in Raw Text            | Template Solution                                         |
|----------------------------------|-----------------------------------------------------------|
| Vague or nested claims           | Probed extraction with slot definitions                   |
| Implicit assumptions             | Required justification from source text                  |
| Mixed levels of abstraction      | Segmented modules: concepts, methods, parameters          |
| Semantic drift across papers     | Schema enforcement and alignment                          |
| Missing or inconsistent fields   | Gap detection + template evolution                        |

---

## 5.2 Template Design Structure

Templates are **modular**, field-specific, and written in structured plain text (Markdown, JSON, YAML). Each template acts as an analytical contract that an LLM must satisfy.

The design of each distillation template is modular and interpretable, built to interface cleanly with LLMs while remaining readable by humans. Each template reflects domain-specific expectations, capturing how a particular field structures its reasoning. Templates function like scaffolds — outlining the cognitive anatomy of scientific claims — and prompting LLMs to extract each structural piece with clarity and traceability.

### Key Features

| Feature                    | Description                                                           |
|----------------------------|-----------------------------------------------------------------------|
| **Schema-conformance**     | Each field maps to a known node or edge type in the Universal Schema  |
| **Justification Required** | LLM must quote or reference exact source text for each extracted item |
| **Slot Typing**            | Values must conform to expected formats (e.g., number, unit, DOI)      |
| **Scoring Rubrics**        | Prompts LLM to assess e.g. replicability, clarity, constraint          |
| **Meta-probes**            | Ask LLMs whether the template missed anything important                |

### Example: Template Modules (Field: Intelligent Soft Matter)

As a concrete example, the table below outlines how a field-specific template (in this case, for intelligent soft matter) is segmented into logical modules. Each module isolates a class of information — from metadata to mechanisms to limitations — that can be probed in isolation, verified independently, and composed into structured artifacts. This modular breakdown supports better prompt engineering, targeted refinement, and high-granularity synthesis downstream.

| Module ID | Title                      | Example Output                             |
|-----------|----------------------------|--------------------------------------------|
| M0        | Metadata                   | DOI, Authors, Year                         |
| M1        | Core Claims                | "Material X adapts to stimulus Y"          |
| M2        | System Description         | "Hydrogel matrix embedded with circuit"    |
| M3        | Mechanism & Function       | "Swelling activates a feedback loop"       |
| M4        | Parameter Specification    | "Swelling time = 3s @ 22°C"                |
| M5        | Results & Observations     | "Adaptive stiffness increased by 40%"      |
| M6        | Limitations & Gaps         | "No dynamic fatigue testing reported"      |

---

## 5.3 Extraction Process with Templates

The extraction process operates in discrete steps, from LLM prompting to validation and artifact registration. This multistage pipeline ensures not only that extracted content aligns with expected schema but also that each claim is backed by clear provenance. The template acts as a dynamic questionnaire, and the LLM serves as a semantic translator — converting prose into a structured, computable form.

1. **Scope Definition**: Select field-specific template version  
2. **LLM Prompting**: Load the template into the prompt along with the source paper  
3. **Extraction**: LLM fills out each field with:
   - Canonicalised values
   - Direct textual support
   - Confidence and rubrics  
4. **Validation Layer**:
   - Format-checks
   - Source-reference linkage
   - Schema alignment  
5. **Artifact Registration**:
   - Adds extracted items into CNM
   - Flags inconsistencies
   - Computes initial scores

---

## 5.4 Self-Consistent Refinement Loop

Templates aren’t static — they evolve based on how well they capture the actual structure of a domain.

### Refinement Workflow

Templates aren’t static: they evolve over time in response to corpus feedback. This feedback loop forms a self-consistent refinement process, where each cycle through the literature reveals mismatches, gaps, or redundant structure in the template — prompting an update. The goal is to converge toward a schema that mirrors the actual shape of knowledge within a domain.

```plaintext
[Template v0]
    ↓
[LLM extraction on batch corpus]
    ↓
[Aggregated feedback]
    ↓
[Schema mismatch analysis]
    ↓
[Template v1 with updated slots, examples, or probes]
    ↓
Repeat until convergence
```

### Types of Feedback Signals

Feedback signals are gathered from the system's own behaviour — as well as from LLM self-evaluation and corpus-wide patterns. These signals help identify when a template is underperforming, when the domain has shifted semantically, or when new concepts are emerging that fall outside of current slot expectations.

| Source                         | Example Insight                                            |
|--------------------------------|------------------------------------------------------------|
| **Missing field patterns**     | "Swelling rate" appears often but isn’t in the template    |
| **LLM self-assessment**        | “Template failed to capture emergent behaviour logic”      |
| **Low artifact alignment**     | Same claim rendered differently across papers              |
| **Redundant fields**           | Multiple fields always contain overlapping values          |
| **Concept drift**              | Term 'intelligence' evolves — needs new slot for criteria  |

Templates adapt toward a **dynamically stabilised schema** reflective of the collective structure of knowledge in that field.

---

## 5.5 Analogies and Inspirations

The template system’s evolution borrows ideas from a variety of disciplines — from physics to programming to biology. These analogies frame the refinement loop not just as a mechanical correction mechanism, but as a form of epistemic evolution: templates adapt to represent an increasingly accurate and general model of how a domain expresses knowledge.

The refinement loop draws from several well-known patterns:

| Analogy                    | Description                                                    |
|----------------------------|----------------------------------------------------------------|
| **Self-consistent field theory (physics)** | Template converges to reflect the field structure  |
| **Compiler grammars**      | Strict formal structure with typed expectations                |
| **Biological evolution**   | Iterative fitness-improving adaptation to conceptual ecosystem |
| **Meta-learning**          | Template learns how to learn from the corpus                   |

---

## 5.6 Benefits of the Template System

The use of a structured, evolving template system confers multiple systemic benefits — from improved consistency and traceability to greater robustness and adaptability. Rather than viewing templates as rigid constraints, they are best understood as dynamic conceptual frameworks that help align AI outputs with human logic and scientific norms.

| Benefit                   | Explanation                                                    |
|---------------------------|----------------------------------------------------------------|
| **Consistency**           | Enforces structural regularity across extractions              |
| **Traceability**          | All outputs traceable to source phrases                        |
| **Robustness**            | Reduces hallucination and forces schema conformance            |
| **Adaptability**          | Evolves as fields change or new artefact types emerge          |
| **Domain-specificity**    | Supports unique vocabularies and epistemic norms per field     |

---

## 5.7 Edge Cases and Mitigation

Like any schema-driven system, the template approach must contend with edge cases. These include ambiguous phrasing, out-of-schema knowledge, and LLM-specific risks like hallucination. The mitigation strategies below are built into both the LLM prompting layer and the validation layer, ensuring resilience and interpretability.

| Risk                          | Safeguard                                                        |
|-------------------------------|------------------------------------------------------------------|
| LLM hallucination             | Justification and reference checks                              |
| Schema misspecification       | Meta-probes and feedback signals from extraction                 |
| Incomplete mapping            | Semi-automated gap detection and refinement                      |
| Overfitting to narrow corpus  | Cross-domain benchmarking and generalisability audits           |

---

## 5.8 Template Lifecycle

Template development is version-controlled and transparent. New templates are born from initial domain analysis or expert design; then refined iteratively based on real-world extraction performance. Each version is archived, and changes are documented to support reproducibility and auditability over time.

Templates go through versioned development:

```plaintext
Template v0: Expert-designed schema
Template v1: Initial LLM feedback
Template v2: Field-specific adjustments
Template v3: Post gap-analysis synthesis
Template vN: Domain-stable consensus schema
```

Each template version is saved, versioned, and associated with a provenance chain.

---

> ☑️ Visual prompt for napkin.ai:
>
> **Title**: “Adaptive Template Refinement Loop”
>
> - Circular loop diagram:
>     - Start: “Template v0”
>     - Then: “LLM Extraction”
>     - Then: “Corpus Feedback”
>     - Then: “Schema Update”
>     - Loop arrow: back to “Template v1”
>
> - Side panels:
>     - Top: “Template Modules” (M0–M6)
>     - Bottom-left: “Field-Specific Slots” (e.g., parameters, mechanisms)
>     - Bottom-right: “Meta-Probes” (“What was missed?”)
>
> - Footer: “Goal: Schema ↔ Corpus Alignment”
